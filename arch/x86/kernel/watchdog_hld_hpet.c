// SPDX-License-Identifier: GPL-2.0
/*
 * A hardlockup detector driven by an HPET timer.
 *
 * Copyright (C) Intel Corporation 2019
 *
 * A hardlockup detector driven by an HPET timer. It implements the same
 * interfaces as the PERF-based hardlockup detector.
 *
 * In order to minimize the reconfiguration of interrupts, the HPET timer
 * always targets the same CPU (the first CPU present in the
 * watchdog_allowed_mask cpumask, the handling CPU). If the HPET caused
 * an NMI on the handling CPU, an NMI interprocessor interrupt is sent
 * to the other CPUs in the watchdog_allowed_mask.
 */

#define pr_fmt(fmt) "hpet-nmi-watchdog: " fmt

#include <linux/nmi.h>
#include <linux/hpet.h>
#include <asm/msidef.h>
#include <asm/hpet.h>

static struct hpet_hld_data *hld_data;
static bool hardlockup_use_hpet;

static inline unsigned long get_count(void)
{
	return hpet_readq(HPET_COUNTER);
}

static inline void set_comparator(struct hpet_hld_data *hdata,
				  unsigned long cmp)
{
	hpet_writeq(cmp, HPET_Tn_CMP(hdata->num));
}

/**
 * kick_timer() - Reprogram timer to expire in the future
 * @hdata:	A data structure with the timer instance to update
 * @force:	Force reprogram. Useful enabling or re-enabling detector.
 *
 * Reprogram the timer to expire within watchdog_thresh seconds in the future.
 *
 */
static void kick_timer(struct hpet_hld_data *hdata, bool force)
{
	bool kick_needed = force || !(hdata->has_periodic);
	unsigned long new_compare, count;

	/*
	 * Update the comparator in increments of watch_thresh seconds relative
	 * to the current count. Since watch_thresh is given in seconds, we
	 * are able to update the comparator before the counter reaches such new
	 * value.
	 *
	 * Let it wrap around if needed.
	 */

	if (!kick_needed)
		return;

	count = get_count();
	new_compare = count + watchdog_thresh * hdata->ticks_per_second;
	set_comparator(hdata, new_compare);
}

static void disable_timer(struct hpet_hld_data *hdata)
{
	unsigned int v;

	v = hpet_readl(HPET_Tn_CFG(hdata->num));
	v &= ~HPET_TN_ENABLE;
	hpet_writel(v, HPET_Tn_CFG(hdata->num));
}

static void enable_timer(struct hpet_hld_data *hdata)
{
	unsigned long v;

	v = hpet_readl(HPET_Tn_CFG(hdata->num));
	v |= HPET_TN_ENABLE;
	hpet_writel(v, HPET_Tn_CFG(hdata->num));
}

/**
 * set_periodic() - Set an HPET timer instance in periodic mode
 * @hdata:	A data structure with the timer instance to enable
 *
 * If the timer supports periodic mode, configure it in such mode.
 * Returns:
 */
static void set_periodic(struct hpet_hld_data *hdata)
{
	unsigned long v;

	if (!(hdata->has_periodic))
		return;

	v = hpet_readl(HPET_Tn_CFG(hdata->num));
	v |= HPET_TN_PERIODIC;
	hpet_writel(v, HPET_Tn_CFG(hdata->num));
}

/**
 * is_hpet_wdt_interrupt() - Determine if an HPET timer caused interrupt
 * @hdata:	A data structure with the timer instance to enable
 *
 * Returns:
 * True if the HPET watchdog timer caused the interrupt. False otherwise.
 */
static bool is_hpet_wdt_interrupt(struct hpet_hld_data *hdata)
{
	return false;
}

/**
 * compose_msi_msg() - Populate address and data fields of an MSI message
 * @hdata:	A data strucure with the message to populate
 *
 * Populate an MSI message to deliver an NMI interrupt. Fields are populated
 * as in the MSI interrupt domain. This function does not populate the
 * Destination ID.
 *
 * Returns: none
 */
static void compose_msi_msg(struct hpet_hld_data *hdata)
{
	struct msi_msg *msg = &hdata->msi_msg;

	/*
	 * The HPET FSB Interrupt Route register does not have an
	 * address_hi part.
	 */
	msg->address_lo = MSI_ADDR_BASE_LO;

	if (apic->irq_dest_mode == 0)
		msg->address_lo |= MSI_ADDR_DEST_MODE_PHYSICAL;
	else
		msg->address_lo |= MSI_ADDR_DEST_MODE_LOGICAL;

	msg->address_lo |= MSI_ADDR_REDIRECTION_CPU;

	/*
	 * On edge trigger, we don't care about assert level. Also,
	 * since delivery mode is NMI, no irq vector is needed.
	 */
	msg->data = MSI_DATA_TRIGGER_EDGE | MSI_DATA_LEVEL_ASSERT |
		    MSI_DATA_DELIVERY_NMI;
}

/** update_msi_msg() - Update APIC destid of handling CPU
 * @hdata:	A data strucure with the MSI message to update
 *
 * Update the APIC destid of the MSI message generated by the HPET timer
 * on expiration.
 */
static int update_msi_msg(struct hpet_hld_data *hdata)
{
	unsigned int destid;

	hdata->msi_msg.address_lo &= ~MSI_ADDR_DEST_ID_MASK;
	destid = apic->calc_dest_apicid(hdata->handling_cpu);
	hdata->msi_msg.address_lo |= MSI_ADDR_DEST_ID(destid);

	hpet_writel(hdata->msi_msg.address_lo, HPET_Tn_ROUTE(hdata->num) + 4);

	return 0;
}

/**
 * hardlockup_detector_nmi_handler() - NMI Interrupt handler
 * @val:	Attribute associated with the NMI. Not used.
 * @regs:	Register values as seen when the NMI was asserted
 *
 * Handle an NMI interrupt. Check if it was caused by the expiration of the
 * HPET timer. If yes, create a CPU mask to issue an IPI to the rest of
 * monitored CPUs. Upon receiving their own NMI, the other CPUs will
 * check such mask to determine if they need to also look for lockups.
 *
 * Returns:
 * NMI_DONE if the HPET timer did not cause the interrupt. NMI_HANDLED
 * otherwise.
 */
static int hardlockup_detector_nmi_handler(unsigned int val,
					   struct pt_regs *regs)
{
	struct hpet_hld_data *hdata = hld_data;
	unsigned int cpu = smp_processor_id();

	if (!is_hpet_wdt_interrupt(hdata))
		return NMI_DONE;

	inspect_for_hardlockups(regs);

	cpu = cpumask_next(cpu, to_cpumask(hdata->cpu_monitored_mask));
	if (cpu >= nr_cpu_ids)
		cpu = cpumask_first(to_cpumask(hdata->cpu_monitored_mask));

	hdata->handling_cpu = cpu;
	update_msi_msg(hdata);
	kick_timer(hdata, !(hdata->has_periodic));

	return NMI_HANDLED;
}

/**
 * setup_irq_msi_mode() - Configure the timer to deliver an MSI interrupt
 * @data:	Data associated with the instance of the HPET timer to configure
 *
 * Configure an instance of the HPET timer to deliver interrupts via the Front-
 * Side Bus.
 *
 * Returns:
 * 0 success. An error code in configuration was unsuccessful.
 */
static int setup_irq_msi_mode(struct hpet_hld_data *hdata)
{
	unsigned int v;

	compose_msi_msg(hdata);
	hpet_writel(hdata->msi_msg.data, HPET_Tn_ROUTE(hdata->num));
	hpet_writel(hdata->msi_msg.address_lo, HPET_Tn_ROUTE(hdata->num) + 4);

	/*
	 * Since FSB interrupt delivery is used, configure as edge-triggered
	 * interrupt.
	 */
	v = hpet_readl(HPET_Tn_CFG(hdata->num));
	v &= ~HPET_TN_LEVEL;
	v |= HPET_TN_FSB;

	hpet_writel(v, HPET_Tn_CFG(hdata->num));

	return 0;
}

/**
 * setup_hpet_irq() - Configure the interrupt delivery of an HPET timer
 * @data:	Data associated with the instance of the HPET timer to configure
 *
 * Configure the interrupt parameters of an HPET timer. If supported, configure
 * interrupts to be delivered via the Front-Side Bus. Also, install an interrupt
 * handler.
 *
 * Returns:
 * 0 success. An error code in configuration was unsuccessful.
 */
static int setup_hpet_irq(struct hpet_hld_data *hdata)
{
	int ret;

	ret = setup_irq_msi_mode(hdata);
	if (ret)
		return ret;

	ret = register_nmi_handler(NMI_LOCAL, hardlockup_detector_nmi_handler,
				   0, "hpet_hld");

	return ret;
}

/**
 * hardlockup_detector_hpet_enable() - Enable the hardlockup detector
 * @cpu:	CPU Index in which the watchdog will be enabled.
 *
 * Enable the hardlockup detector in @cpu. This means adding it to the
 * cpumask of monitored CPUs. If @cpu is the first one for which the
 * hardlockup detector is enabled, it will handle the interrupts from the
 * HPET timer.
 */
void hardlockup_detector_hpet_enable(unsigned int cpu)
{
	cpumask_set_cpu(cpu, to_cpumask(hld_data->cpu_monitored_mask));

	if (!hld_data->enabled_cpus++) {
		hld_data->handling_cpu = cpu;
		update_msi_msg(hld_data);
		/* Force timer kick when detector is just enabled */
		kick_timer(hld_data, true);
		enable_timer(hld_data);
	}

	/*
	 * When in periodic mode, only this function kicks the timer. Hence,
	 * as there are now more CPUs to monitor, we need to adjust the
	 * periodic expiration.
	 */
	kick_timer(hld_data, hld_data->has_periodic);
}

/**
 * hardlockup_detector_hpet_disable() - Disable the hardlockup detector
 * @cpu:	CPU index in which the watchdog will be disabled
 *
 * @cpu is removed from the cpumask of monitored CPUs. If @cpu handles the
 * interrupts from the HPET timer, update the handling CPU to the next
 * available, monitored CPU.
 */
void hardlockup_detector_hpet_disable(unsigned int cpu)
{
	cpumask_clear_cpu(cpu, to_cpumask(hld_data->cpu_monitored_mask));
	hld_data->enabled_cpus--;

	if (hld_data->handling_cpu != cpu)
		return;

	disable_timer(hld_data);
	if (!hld_data->enabled_cpus)
		return;

	cpu = cpumask_first(to_cpumask(hld_data->cpu_monitored_mask));
	hld_data->handling_cpu = cpu;
	update_msi_msg(hld_data);
	enable_timer(hld_data);
}

void hardlockup_detector_hpet_stop(void)
{
	disable_timer(hld_data);
}

/**
 * hardlockup_detector_hpet_init() - Initialize the hardlockup detector
 *
 * Only initialize and configure the detector if an HPET is available on the
 * system.
 *
 * Returns:
 * 0 success. An error code if initialization was unsuccessful.
 */
int __init hardlockup_detector_hpet_init(void)
{
	int ret = -ENODEV;

	if (!hardlockup_use_hpet)
		return -ENODEV;

	if (!is_hpet_enabled())
		return -ENODEV;

	if (check_tsc_unstable())
		return -ENODEV;

	hld_data = hpet_hardlockup_detector_assign_timer();
	if (!hld_data)
		return -ENODEV;

	disable_timer(hld_data);

	set_periodic(hld_data);

	ret = setup_hpet_irq(hld_data);
	if (ret) {
		kfree(hld_data);
		hld_data = NULL;
	}

	return ret;
}
